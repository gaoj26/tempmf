{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRMF: temporal regularized matrix factorization\n",
    "\n",
    ">**Reference**: Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon, 2016. [*Temporal regularized matrix factorization for high-dimensional time series prediction*](http://www.cs.utexas.edu/~rofuyu/papers/tr-mf-nips.pdf). 30th Conference on Neural Information Processing Systems (*NIPS 2016*), Barcelona, Spain. [[Matlab code](https://github.com/rofuyu/exp-trmf-nips16)]\n",
    "\n",
    "## 1. Matrix factorization\n",
    "\n",
    "### 1.1. Matrix factorization and a novel <span style=\"color:blue\">autoregressive temporal regularizer</span>\n",
    "\n",
    "Consider a commonly used <span style=\"color:blue\">matrix factorization</span> for completion task:\n",
    "\n",
    "$$Y=WX^T$$\n",
    "where $W\\in\\mathbb{R}^{m\\times r},X\\in\\mathbb{R}^{n\\times r}$ are factor matrices decomposed from data matrix $Y\\in\\mathbb{R}^{m\\times n}$. We can also treat matrix $Y$ as <span style=\"color:blue\">a $m$-dimensional time series</span> with <span style=\"color:blue\">$y_{it}$ being the observation at the $t$-th time slot of the $i$-th time series</span>.\n",
    "\n",
    "In order to model the temporal dependence with time order, we assume that\n",
    "\n",
    "$$\\boldsymbol{x}_{t}\\approx\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}$$\n",
    "where this autoregressive (AR) is specialized by <span style=\"color:blue\">a lag set $\\mathcal{L}=\\left\\{l_1,l_2,...,l_d\\right\\}$ (e.g., $\\mathcal{L}=\\left\\{1,2,144\\right\\}$)</span> and <span style=\"color:blue\">weights $\\boldsymbol{\\theta}_{l}\\in\\mathbb{R}^{r},\\forall l$</span>, and we further define\n",
    "\n",
    "$$\\mathcal{R}_{AR}\\left(X\\mid \\mathcal{L},\\Theta,\\eta\\right)=\\frac{1}{2}\\sum_{t=l_d+1}^{n}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^T\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)+\\frac{\\eta}{2}\\sum_{t=1}^{n}\\boldsymbol{x}_{t}^T\\boldsymbol{x}_{t}.$$\n",
    "\n",
    "Thus, <span style=\"color:blue\">TRMF-AR</span> is given by solving\n",
    "\n",
    "<span style=\"color:blue\">$$\\min_{W,X,\\Theta}\\frac{1}{2}\\underbrace{\\sum_{(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^T\\boldsymbol{x}_{t}\\right)^2}_{\\text{sum of squared residual errors}}+\\lambda_{w}\\underbrace{\\mathcal{R}_{w}\\left(W\\right)}_{W-\\text{regularizer}}+\\lambda_{x}\\underbrace{\\mathcal{R}_{AR}\\left(X\\mid \\mathcal{L},\\Theta,\\eta\\right)}_{\\text{AR-regularizer}}+\\lambda_{\\theta}\\underbrace{\\mathcal{R}_{\\theta}\\left(\\Theta\\right)}_{\\Theta-\\text{regularizer}}$$</span>\n",
    "where $\\mathcal{R}_{w}\\left(W\\right)=\\frac{1}{2}\\sum_{i=1}^{m}\\boldsymbol{w}_{i}^T\\boldsymbol{w}_{i}$ and $\\mathcal{R}_{\\theta}\\left(\\Theta\\right)=\\frac{1}{2}\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}^T\\boldsymbol{\\theta}_{l}$ are regularization terms.\n",
    "\n",
    "> **Model weakness**: <span style=\"color:red\">weights of regularizers $\\left\\{\\lambda_{w},\\lambda_{x},\\lambda_{\\theta}\\right\\}$ are not easy to determine!</span>\n",
    "\n",
    "### 1.2. Learning <span style=\"color:blue\">spatial and temporal embeddings</span>\n",
    "\n",
    "***Alternating minimization***:\n",
    "\n",
    "#### 1.2.1. Updates for $W\\in\\mathbb{R}^{m\\times r}$\n",
    "\n",
    "> Fast algorithms such as <span style=\"color:blue\">alternating least squares or coordinate descent</span> can be applied directly to find $W$.\n",
    "\n",
    "Solving\n",
    "\n",
    "<span style=\"color:blue\">$$\\min_{W}\\frac{1}{2}\\underbrace{\\sum_{(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^T\\boldsymbol{x}_{t}\\right)^2}_{\\text{sum of squared residual errors}}+\\frac{1}{2}\\lambda_{w}\\underbrace{\\sum_{i=1}^{m}\\boldsymbol{w}_{i}^T\\boldsymbol{w}_{i}}_{\\text{sum of squared entries}}$$</span>\n",
    "\n",
    "by alternative least square for $\\boldsymbol{w}_{i},i=1,2,...,m$.\n",
    "\n",
    "<span style=\"color:red\">$$\\boldsymbol{w}_{i}\\Leftarrow\\left(\\sum_{i:(i,t)\\in\\Omega}\\boldsymbol{x}_{t}\\boldsymbol{x}_{t}^T+\\lambda_{w}I\\right)^{-1}\\sum_{i:(i,t)\\in\\Omega}y_{it}\\boldsymbol{x}_{t}$$</span>\n",
    "\n",
    "#### 1.2.2. Updates for $X\\in\\mathbb{R}^{n\\times r}$\n",
    "\n",
    "Solving\n",
    "\n",
    "<span style=\"color:blue\">$$\\min_{X}\\frac{1}{2}\\underbrace{\\sum_{(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^T\\boldsymbol{x}_{t}\\right)^2}_{\\text{sum of squared residual errors}}\n",
    "+\\frac{1}{2}\\lambda_{x}\\underbrace{\\sum_{t=l_d+1}^{n}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^T\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)}_{\\text{sum of squared residual errors}}\n",
    "+\\frac{1}{2}\\lambda_{x}\\eta\\underbrace{\\sum_{t=1}^{n}\\boldsymbol{x}_{t}^T\\boldsymbol{x}_{t}}_{\\text{sum of squared entries}}$$</span>\n",
    "\n",
    "- For any $t\\in\\left\\{1,2,...,n\\right\\}$, we have\n",
    "\n",
    "$$\\underbrace{\\sum_{t:(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^{T}\\boldsymbol{x}_{t}\\right)^2}_{\\text{sum of squared residual errors}}=\\sum_{t:(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^{T}\\boldsymbol{x}_{t}\\right)^T\\left(y_{it}-\\boldsymbol{w}_{i}^{T}\\boldsymbol{x}_{t}\\right)$$\n",
    "\n",
    "$$=\\boldsymbol{x}_{t}^{T}\\left(\\sum_{t:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}\\boldsymbol{w}_{i}^{T}\\right)\\boldsymbol{x}_{t}-\\boldsymbol{x}_{t}^{T}\\left(\\sum_{t:(i,t)\\in\\Omega}y_{it}\\boldsymbol{w}_{i}\\right)-\\left(\\sum_{t:(i,t)\\in\\Omega}y_{it}\\boldsymbol{w}_{i}^T\\right)\\boldsymbol{x}_{t}+\\text{const}$$\n",
    "\n",
    "- For any $t\\in\\left\\{l_d+1,...,n-l_d\\right\\}$, we have\n",
    "\n",
    "$$\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^T\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)+\\cdots$$\n",
    "$$\\underbrace{+\\left(\\boldsymbol{x}_{t+l_d}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t+l_d-l}\\right)^T\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t+l_d-l}\\right)}_{\\text{sum of squared residual errors}}$$\n",
    "\n",
    "$$=\\boldsymbol{x}_{t}^{T}\\boldsymbol{x}_{t}-\\boldsymbol{x}_{t}^{T}\\left(\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)-\\left(\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^T\\boldsymbol{x}_{t}\n",
    "+\\sum_{h\\in\\mathcal{L}}\\left(\\boldsymbol{\\psi}_{t+h}-\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{x}_{t}\\right)^T\\left(\\boldsymbol{\\psi}_{t+h}-\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{x}_{t}\\right)+\\text{const}$$\n",
    "\n",
    "$$=\\boldsymbol{x}_{t}^T\\left(I+\\sum_{h\\in\\mathcal{L}}\\text{diag}(\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\theta}_{h})\\right)\\boldsymbol{x}_{t}-\\boldsymbol{x}_{t}^{T}\\left(\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}+\\sum_{h\\in\\mathcal{L}}\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\psi}_{t+h}\\right)+\\text{const}$$\n",
    "\n",
    "where $\\boldsymbol{\\psi}_{t+h}=\\boldsymbol{x}_{t+h}-\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t+h-l}$.\n",
    "\n",
    "Thus, for <span style=\"color:red\">$t=h_d+1,...,n-h_d$</span>, we can update $\\boldsymbol{x}_{t}$ by\n",
    "\n",
    "<span style=\"color:red\">$$\\boldsymbol{x}_{t}\\Leftarrow\\left(\\sum_{t:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}\\boldsymbol{w}_{i}^{T}+\\left(\\lambda_{x}+\\lambda_{x}\\eta\\right)I+\\lambda_{x}\\sum_{h\\in\\mathcal{L}}\\text{diag}\\left(\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\theta}_{h}\\right)\\right)^{-1}\\left(\\sum_{t:(i,t)\\in\\Omega}y_{it}\\boldsymbol{w}_{i}+\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}+\\sum_{h\\in\\mathcal{L}}\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\psi}_{t+h}\\right)$$</span>\n",
    "\n",
    "#### 1.2.3. Updates for $\\Theta\\in\\mathbb{R}^{r\\times |\\mathcal{L}|}$\n",
    "\n",
    "Solving the following optimization problem:\n",
    "\n",
    "<span style=\"color:blue\">$$\\min_{\\Theta}\\frac{1}{2}\\lambda_{x}\\underbrace{\\sum_{t=l_d+1}^{n}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^T\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)}_{\\text{sum of squared residual errors}}\n",
    "+\\frac{1}{2}\\lambda_{\\theta}\\underbrace{\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}^T\\boldsymbol{\\theta}_{l}}_{\\text{sum of squared entries}}$$</span>\n",
    "\n",
    "For any $\\boldsymbol{\\theta}_{h},\\forall h\\in\\mathcal{L}$,\n",
    "\n",
    "$$\\underbrace{\\sum_{t=l_d+1}^{n}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}-\\text{diag}(\\boldsymbol{x}_{t-h})\\boldsymbol{\\theta}_{h}\\right)^T\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}-\\text{diag}(\\boldsymbol{x}_{t-h})\\boldsymbol{\\theta}_{h}\\right)}_{\\text{sum of squared residual errors}}+\\frac{\\lambda_{\\theta}}{\\lambda_{x}}\\boldsymbol{\\theta}_{h}^{T}\\boldsymbol{\\theta}_{h}$$\n",
    "\n",
    "suppose that $\\boldsymbol{\\pi}_{t}^{(h)}=\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}$, we can update $\\boldsymbol{\\theta}_{h}$ by\n",
    "\n",
    "<span style=\"color:red\">$$\\boldsymbol{\\theta}_{h}\\Leftarrow\\left(\\sum_{t=l_d+1}^{n}\\text{diag}(\\boldsymbol{x}_{t-h}\\circledast\\boldsymbol{x}_{t-h})+\\frac{\\lambda_{\\theta}}{\\lambda_{x}}I\\right)^{-1}\\sum_{t=l_d+1}^{n}\\text{diag}(\\boldsymbol{x}_{t-h})\\boldsymbol{\\pi}_{t}^{h}$$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kernels and implementation\n",
    "\n",
    ">**Kernel**: Updating $W\\in\\mathbb{R}^{m\\times r}$\n",
    "\n",
    "$$\\boldsymbol{w}_{i}\\Leftarrow\\left(\\sum_{i:(i,t)\\in\\Omega}\\boldsymbol{x}_{t}\\boldsymbol{x}_{t}^T+\\lambda_{w}I\\right)^{-1}\\sum_{i:(i,t)\\in\\Omega}y_{it}\\boldsymbol{x}_{t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_w"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    update_w(Y,X,lambda_w)\n",
    "Inputs: Y(m*n), X(m*r), lambda_w(scalar).\n",
    "\"\"\"\n",
    "function update_w(Y,X,lambda_w)\n",
    "    W = zeros(size(Y,1),size(X,2))\n",
    "    for i in [1:size(Y,1)]\n",
    "        bin = zeros(length(Y[i,:]))\n",
    "        bin[find(Y[i,:])] = 1\n",
    "        W[i,:] = inv((bin'*X)'*(bin'*X)+lambda_w)*(Y[i,:]'*X)'\n",
    "    end\n",
    "    return W\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Kernel**: Updating $X\\in\\mathbb{R}^{n\\times r}$\n",
    "\n",
    "For $t=h_d+1,...,n-h_d$, we can update $\\boldsymbol{x}_{t}$ by\n",
    "\n",
    "$$\\boldsymbol{x}_{t}\\Leftarrow\\left(\\sum_{t:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}\\boldsymbol{w}_{i}^{T}+\\left(\\lambda_{x}+\\lambda_{x}\\eta\\right)I+\\lambda_{x}\\sum_{h\\in\\mathcal{L}}\\text{diag}\\left(\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\theta}_{h}\\right)\\right)^{-1}\\left(\\sum_{t:(i,t)\\in\\Omega}y_{it}\\boldsymbol{w}_{i}+\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}+\\sum_{h\\in\\mathcal{L}}\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\psi}_{t+h}\\right)$$\n",
    "where $\\boldsymbol{\\psi}_{t+h}=\\boldsymbol{x}_{t+h}-\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t+h-l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_x"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    update_x(Y,W,X,theta,Lags,lambda_x,eta)\n",
    "Inputs: Y(m*n), W(m*r), X(n*r), theta(d*r), Lags(d*1), lambda_x(scalar), eta(scalar).\n",
    "\"\"\"\n",
    "function update_x(Y,W,X,theta,Lags,lambda_x,eta)\n",
    "    r = size(X,2)\n",
    "    for t in [1:size(X,1)]\n",
    "        bin = zeros(length(Y[:,t]))\n",
    "        bin[find(Y[:,t])] = 1\n",
    "        var1 = (bin'*W)'*(bin'*W)+lambda_x*eta*diagm(ones(r))\n",
    "        var2 = (Y[:,t]'*W)'\n",
    "        if t <= max(Lags)\n",
    "            Pt = zeros(r,r);\n",
    "            Qt = zeros(r);\n",
    "        else\n",
    "            Pt = diagm(ones(r));\n",
    "            Qt = sum(theta.*X[t-Lags,:],1)';\n",
    "        end\n",
    "        if t <= size(X,1)-min(Lags)\n",
    "            if t > max(Lags) && t <= size(X,1)-max(Lags)\n",
    "                index = [1:d]\n",
    "            else\n",
    "                index = find(x->(x>max(Lags) & x<size(X,1)),t+Lags)\n",
    "            end\n",
    "            Mk = zeros(r,r)\n",
    "            Nk = zeros(r)\n",
    "            for k in index\n",
    "                Mk = zeros(r,r)+lambda_x*diagm(theta[k,:].*theta[k,:])\n",
    "                Nk = zeros(r)+theta[k,:].*(X[t+Lags[k],:]-sum(theta.*X[t+Lags[k]-Lags,:],1)'+theta[k,:].*X[t,:])\n",
    "            end\n",
    "            X[t,:] = inv(var1+lambda_x*Pt+lambda_x*Mk)*(var2+Qt+Nk)\n",
    "        else\n",
    "            X[t,:] = inv(var1+lambda_x*diagm(ones(r)))*(var2+sum(theta.*X[t-Lags,:],1)')\n",
    "        end\n",
    "    end\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Kernel**: Updating $\\Theta\\in\\mathbb{R}^{d\\times r}$\n",
    "\n",
    "$$\\boldsymbol{\\theta}_{h}\\Leftarrow\\left(\\sum_{t=l_d+1}^{n}\\text{diag}(\\boldsymbol{x}_{t-h}\\circledast\\boldsymbol{x}_{t-h})+\\frac{\\lambda_{\\theta}}{\\lambda_{x}}I\\right)^{-1}\\sum_{t=l_d+1}^{n}\\text{diag}(\\boldsymbol{x}_{t-h})\\boldsymbol{\\pi}_{t}^{h}$$\n",
    "where $\\boldsymbol{\\pi}_{t}^{(h)}=\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_theta"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    update_theta(X,theta,Lags,lambda_x,lambda_theta)\n",
    "Inputs: X(n*r), theta(d*r), Lags(d*1), lambda_x(scalar),lambda_theta(scalar).\n",
    "\"\"\"\n",
    "function update_theta(X,theta,Lags,lambda_x,lambda_theta)\n",
    "    d = size(theta,1)\n",
    "    r = size(theta,2)\n",
    "    for k in [1:d]\n",
    "        var1 = X[max(Lags)+1-Lags[k]:size(X,1)-Lags[k],:]\n",
    "        var2 = inv(diagm(sum(var1.*var1,1))+lambda_theta/lambda_x*diagm(ones(r)))\n",
    "        var3 = zeros(r)\n",
    "        for t in [max(Lags)+1-Lags[k]:size(X,1)-Lags[k]]\n",
    "            var3 = zeros(r)+X[t,:].*(X[t+Lags[k],:]-sum(theta.*X[t+Lags[k]-Lags,:],1)'+theta[k,:].*X[t,:])\n",
    "        end\n",
    "        theta[k,:] = var2*var3\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Urban traffic speed data set\n",
    "\n",
    "## 4. Missing data imputation\n",
    "\n",
    "## 5. Rolling prediction with incomplete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
